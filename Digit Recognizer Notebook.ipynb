{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Reshape\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "target = 'label'\n",
    "trainSplitRandomSeed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = training.loc[:, training.columns != target]\n",
    "X_training = X_training / 255.0\n",
    "test = test / 255.0\n",
    "y_training = training[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_training, y_training, stratify = y_training,\n",
    "                                                                random_state = trainSplitRandomSeed, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_validation = np.array(X_validation).reshape(X_validation.shape[0], 28, 28, 1)\n",
    "test = np.array(test).reshape(test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_validation = np_utils.to_categorical(y_validation, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateNNModel(dropoutRate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropoutRate))\n",
    "    model.add(Dense(10))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnRegressor = KerasClassifier(build_fn=CreateNNModel, verbose=1)\n",
    "\n",
    "estimators = [('nn', nnRegressor)]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "param_grid = {\n",
    "  'nn__dropoutRate': [0.2],\n",
    "  'nn__batch_size' : [500],\n",
    "  'nn__validation_split' : [0.1],\n",
    "  'nn__epochs' : [20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GridSearchCV(pipeline, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 22680 samples, validate on 2520 samples\n",
      "Epoch 1/20\n",
      "22680/22680 [==============================] - 5s 203us/step - loss: 0.2516 - acc: 0.9222 - val_loss: 0.1337 - val_acc: 0.9607\n",
      "Epoch 2/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0481 - acc: 0.9859 - val_loss: 0.0541 - val_acc: 0.9833\n",
      "Epoch 3/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0261 - acc: 0.9937 - val_loss: 0.0542 - val_acc: 0.9841\n",
      "Epoch 4/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0166 - acc: 0.9972 - val_loss: 0.0507 - val_acc: 0.9853\n",
      "Epoch 5/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 0.0103 - acc: 0.9985 - val_loss: 0.0479 - val_acc: 0.9853\n",
      "Epoch 6/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0600 - val_acc: 0.9821\n",
      "Epoch 7/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0040 - acc: 0.9998 - val_loss: 0.0443 - val_acc: 0.9869\n",
      "Epoch 8/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0444 - val_acc: 0.9869\n",
      "Epoch 9/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9873\n",
      "Epoch 10/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9893\n",
      "Epoch 11/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9917\n",
      "Epoch 12/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 9.0464e-04 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9909\n",
      "Epoch 13/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 7.7617e-04 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 0.9905\n",
      "Epoch 14/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 7.0437e-04 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9917\n",
      "Epoch 15/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 5.7888e-04 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9897\n",
      "Epoch 16/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 5.9491e-04 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "Epoch 17/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 4.6861e-04 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9893\n",
      "Epoch 18/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 3.9440e-04 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9913\n",
      "Epoch 19/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 3.5215e-04 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9913\n",
      "Epoch 20/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 3.1276e-04 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9893\n",
      "12600/12600 [==============================] - 0s 33us/step\n",
      "25200/25200 [==============================] - 1s 33us/step\n",
      "Train on 22680 samples, validate on 2520 samples\n",
      "Epoch 1/20\n",
      "22680/22680 [==============================] - 3s 148us/step - loss: 0.2604 - acc: 0.9207 - val_loss: 0.0761 - val_acc: 0.9790\n",
      "Epoch 2/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 0.0435 - acc: 0.9890 - val_loss: 0.0579 - val_acc: 0.9817\n",
      "Epoch 3/20\n",
      "22680/22680 [==============================] - 2s 88us/step - loss: 0.0235 - acc: 0.9950 - val_loss: 0.0429 - val_acc: 0.9873\n",
      "Epoch 4/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 0.0132 - acc: 0.9982 - val_loss: 0.0442 - val_acc: 0.9877\n",
      "Epoch 5/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 0.0083 - acc: 0.9989 - val_loss: 0.0520 - val_acc: 0.9869\n",
      "Epoch 6/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0538 - val_acc: 0.9857\n",
      "Epoch 7/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.0427 - val_acc: 0.9881\n",
      "Epoch 8/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0410 - val_acc: 0.9889\n",
      "Epoch 9/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9889\n",
      "Epoch 10/20\n",
      "22680/22680 [==============================] - 2s 93us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9877\n",
      "Epoch 11/20\n",
      "22680/22680 [==============================] - 2s 94us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9901\n",
      "Epoch 12/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 9.0964e-04 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9909\n",
      "Epoch 13/20\n",
      "22680/22680 [==============================] - 2s 96us/step - loss: 7.3947e-04 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9917\n",
      "Epoch 14/20\n",
      "22680/22680 [==============================] - 2s 94us/step - loss: 6.2531e-04 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9905\n",
      "Epoch 15/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 5.9169e-04 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9905\n",
      "Epoch 16/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 5.5210e-04 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9901\n",
      "Epoch 17/20\n",
      "22680/22680 [==============================] - 2s 89us/step - loss: 5.2215e-04 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9905\n",
      "Epoch 18/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 4.1607e-04 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9901\n",
      "Epoch 19/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 3.6745e-04 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9913\n",
      "Epoch 20/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 3.4878e-04 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 0.9913\n",
      "12600/12600 [==============================] - 0s 32us/step\n",
      "25200/25200 [==============================] - 1s 33us/step\n",
      "Train on 22680 samples, validate on 2520 samples\n",
      "Epoch 1/20\n",
      "22680/22680 [==============================] - 4s 169us/step - loss: 0.2741 - acc: 0.9164 - val_loss: 0.1286 - val_acc: 0.9623\n",
      "Epoch 2/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0475 - acc: 0.9868 - val_loss: 0.0578 - val_acc: 0.9825\n",
      "Epoch 3/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 0.0268 - acc: 0.9933 - val_loss: 0.0576 - val_acc: 0.9798\n",
      "Epoch 4/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 0.0156 - acc: 0.9969 - val_loss: 0.0808 - val_acc: 0.9750\n",
      "Epoch 5/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.0524 - val_acc: 0.9825\n",
      "Epoch 6/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 0.0421 - val_acc: 0.9853\n",
      "Epoch 7/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0037 - acc: 0.9998 - val_loss: 0.0341 - val_acc: 0.9889\n",
      "Epoch 8/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9873\n",
      "Epoch 9/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9897\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22680/22680 [==============================] - 2s 90us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 0.9901\n",
      "Epoch 11/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9881\n",
      "Epoch 12/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9897\n",
      "Epoch 13/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 9.1826e-04 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9897\n",
      "Epoch 14/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 7.4902e-04 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 0.9905\n",
      "Epoch 15/20\n",
      "22680/22680 [==============================] - 2s 91us/step - loss: 6.6358e-04 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9901\n",
      "Epoch 16/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 5.7992e-04 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 0.9909\n",
      "Epoch 17/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 5.0846e-04 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 0.9913\n",
      "Epoch 18/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 4.6718e-04 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9909\n",
      "Epoch 19/20\n",
      "22680/22680 [==============================] - 2s 92us/step - loss: 4.0292e-04 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9917\n",
      "Epoch 20/20\n",
      "22680/22680 [==============================] - 2s 90us/step - loss: 3.6520e-04 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 0.9909\n",
      "12600/12600 [==============================] - 0s 32us/step\n",
      "25200/25200 [==============================] - 1s 32us/step\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/20\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.1849 - acc: 0.9426 - val_loss: 0.0636 - val_acc: 0.9828\n",
      "Epoch 2/20\n",
      "34020/34020 [==============================] - 4s 113us/step - loss: 0.0370 - acc: 0.9890 - val_loss: 0.0466 - val_acc: 0.9852\n",
      "Epoch 3/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0211 - acc: 0.9943 - val_loss: 0.0539 - val_acc: 0.9852\n",
      "Epoch 4/20\n",
      "34020/34020 [==============================] - 4s 113us/step - loss: 0.0242 - acc: 0.9933 - val_loss: 0.0439 - val_acc: 0.9873\n",
      "Epoch 5/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0477 - val_acc: 0.9857\n",
      "Epoch 6/20\n",
      "34020/34020 [==============================] - 4s 112us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0365 - val_acc: 0.9907\n",
      "Epoch 7/20\n",
      "34020/34020 [==============================] - 4s 112us/step - loss: 0.0068 - acc: 0.9988 - val_loss: 0.0337 - val_acc: 0.9915\n",
      "Epoch 8/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0293 - val_acc: 0.9926\n",
      "Epoch 9/20\n",
      "34020/34020 [==============================] - 4s 112us/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0455 - val_acc: 0.9876\n",
      "Epoch 10/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0293 - acc: 0.9905 - val_loss: 0.0678 - val_acc: 0.9833\n",
      "Epoch 11/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0279 - val_acc: 0.9937\n",
      "Epoch 12/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.0351 - val_acc: 0.9910\n",
      "Epoch 13/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0268 - val_acc: 0.9926\n",
      "Epoch 14/20\n",
      "34020/34020 [==============================] - 4s 112us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 0.9937\n",
      "Epoch 15/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 9.2993e-04 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9947\n",
      "Epoch 16/20\n",
      "34020/34020 [==============================] - 4s 111us/step - loss: 7.3461e-04 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9915\n",
      "Epoch 17/20\n",
      "34020/34020 [==============================] - 4s 110us/step - loss: 0.0223 - acc: 0.9932 - val_loss: 0.1125 - val_acc: 0.9712\n",
      "Epoch 18/20\n",
      "34020/34020 [==============================] - 4s 109us/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0389 - val_acc: 0.9899\n",
      "Epoch 19/20\n",
      "34020/34020 [==============================] - 4s 108us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0308 - val_acc: 0.9910\n",
      "Epoch 20/20\n",
      "34020/34020 [==============================] - 4s 108us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0297 - val_acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('nn', <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002006F50C278>)]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'nn__dropoutRate': [0.2], 'nn__batch_size': [500], 'nn__validation_split': [0.1], 'nn__epochs': [20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9914285739262899"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 1s 33us/step\n"
     ]
    }
   ],
   "source": [
    "result = reg.predict(test)\n",
    "resultDf = pd.DataFrame(data=result.flatten())\n",
    "resultDf.columns = ['Label']\n",
    "resultDf = pd.DataFrame(data=result.flatten())\n",
    "resultDf.index = np.arange(1, len(resultDf) + 1)\n",
    "resultDf.to_csv('result.txt', header = ['Label'], index_label = 'ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
